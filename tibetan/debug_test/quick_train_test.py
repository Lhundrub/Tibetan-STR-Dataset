import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from model import CNNTransformer
from data_loader import OCRDataset, collate_fn
from train import compute_loss, decode_predictions
from torch.optim import Adam
from torch.nn.utils import clip_grad_norm_

def quick_train_test():
    """å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ŒéªŒè¯NaNé—®é¢˜å·²è§£å†³"""
    print("=== å¿«é€Ÿè®­ç»ƒæµ‹è¯• ===")
    
    # ä½¿ç”¨ä¼˜åŒ–è¯æ±‡è¡¨
    vocab_path = 'tibetan_vocab_optimized.txt'
    
    # åŠ è½½è¯æ±‡è¡¨
    with open(vocab_path, 'r', encoding='utf-8') as f:
        vocab = [line.strip() for line in f if line.strip()]
    char2idx = {char: idx for idx, char in enumerate(vocab)}
    idx2char = {idx: char for idx, char in enumerate(vocab)}
    vocab_size = len(vocab)
    
    print(f"è¯æ±‡è¡¨å¤§å°: {vocab_size}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = CNNTransformer(vocab_size).to(device)
    optimizer = Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)
    
    # æ•°æ®åŠ è½½
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),
        transforms.Resize((32, 128)),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ])
    
    # ä½¿ç”¨å°æ‰¹é‡æ•°æ®è¿›è¡Œæµ‹è¯•
    train_dataset = OCRDataset('data/train.json', vocab_path, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)
    
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    
    # è®­ç»ƒå‡ ä¸ªæ­¥éª¤
    model.train()
    
    valid_losses = []
    nan_count = 0
    total_batches = 0
    
    print("\nå¼€å§‹è®­ç»ƒæµ‹è¯•...")
    
    for batch_idx, (images, texts, text_lengths, raw_texts) in enumerate(train_loader):
        if batch_idx >= 10:  # åªæµ‹è¯•10ä¸ªbatch
            break
            
        total_batches += 1
        
        images = images.to(device)
        texts = texts.to(device)
        
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        logits = model(images)
        
        # è®¡ç®—æŸå¤±
        loss = compute_loss(logits, texts, text_lengths, blank=0)
        
        # æ£€æŸ¥æŸå¤±
        if torch.isnan(loss) or torch.isinf(loss):
            nan_count += 1
            print(f"Batch {batch_idx + 1}: âŒ æŸå¤±æ— æ•ˆ {loss.item()}")
        else:
            valid_losses.append(loss.item())
            print(f"Batch {batch_idx + 1}: âœ… æŸå¤±æ­£å¸¸ {loss.item():.4f}")
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            clip_grad_norm_(model.parameters(), 1.0)
            
            optimizer.step()
            
            # æµ‹è¯•è§£ç 
            if batch_idx == 0:
                with torch.no_grad():
                    preds = decode_predictions(logits, idx2char, blank=0)
                    print(f"  çœŸå®æ–‡æœ¬: '{raw_texts[0]}'")
                    print(f"  é¢„æµ‹æ–‡æœ¬: '{preds[0]}'")
    
    # ç»“æœæ€»ç»“
    print(f"\n=== æµ‹è¯•ç»“æœ ===")
    print(f"æ€»æ‰¹æ¬¡æ•°: {total_batches}")
    print(f"æœ‰æ•ˆæŸå¤±æ•°: {len(valid_losses)}")
    print(f"NaNé”™è¯¯æ•°: {nan_count}")
    
    if nan_count == 0:
        print("ğŸ‰ æ‰€æœ‰æŸå¤±éƒ½æ­£å¸¸ï¼NaNé—®é¢˜å·²è§£å†³ã€‚")
        if valid_losses:
            avg_loss = sum(valid_losses) / len(valid_losses)
            print(f"å¹³å‡æŸå¤±: {avg_loss:.4f}")
            print(f"æŸå¤±èŒƒå›´: [{min(valid_losses):.4f}, {max(valid_losses):.4f}]")
        return True
    else:
        print(f"âŒ ä»æœ‰ {nan_count} ä¸ªNaNé”™è¯¯")
        return False

if __name__ == "__main__":
    quick_train_test() 