import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from lightning.fabric import Fabric
import argparse
import os
import glob
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import time

# å¯¼å…¥æ‰€æœ‰æ¨¡å‹
from model2 import CNNTransformer
from model_improved1 import CNNTransformerResidual
from model_improved2 import CNNTransformerFPN
from model_improved3 import CNNTransformerAttention
from model_improved4 import CNNBiLSTMTransformer

# å¯¼å…¥è®­ç»ƒæ‰€éœ€å·¥å…·
from data_loader import OCRDataset, collate_fn
from train import compute_loss, decode_predictions, compute_metrics, compute_crr
from train_fixed import compute_error_rates
from torch.optim import Adam
from ocr_transforms import get_ocr_transforms, get_light_augmentation, get_heavy_augmentation

# è®¾ç½®é«˜ç²¾åº¦çŸ©é˜µä¹˜æ³•
torch.set_float32_matmul_precision('high')

# æ¨¡å‹æ˜ å°„å­—å…¸
MODEL_DICT = {
    'base': CNNTransformer,
    'residual': CNNTransformerResidual,
    'fpn': CNNTransformerFPN,
    'attention': CNNTransformerAttention,
    'bilstm': CNNBiLSTMTransformer
}

# æ¨¡å‹ä¸­æ–‡åç§°æ˜ å°„
MODEL_NAMES = {
    'base': 'åŸºç¡€æ¨¡å‹',
    'residual': 'æ®‹å·®è¿æ¥æ¨¡å‹',
    'fpn': 'ç‰¹å¾é‡‘å­—å¡”æ¨¡å‹',
    'attention': 'æ³¨æ„åŠ›æœºåˆ¶æ¨¡å‹',
    'bilstm': 'åŒå‘LSTMæ¨¡å‹'
}

def train_model(model_name, augmentation='medium', epochs=100, batch_size=16, lr=0.0001):
    """
    ä½¿ç”¨Lightning Fabricè®­ç»ƒæŒ‡å®šæ¨¡å‹
    
    Args:
        model_name: è¦è®­ç»ƒçš„æ¨¡å‹åç§°
        augmentation: æ•°æ®å¢å¼ºç±»å‹
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        lr: å­¦ä¹ ç‡
    
    Returns:
        å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹è®­ç»ƒçš„å„é¡¹æŒ‡æ ‡
    """
    # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    os.makedirs('saved_models', exist_ok=True)
    model_dir = Path(f'saved_models/{model_name}')
    model_dir.mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–Fabric (å¯ç”¨16bitæ··åˆç²¾åº¦)
    fabric = Fabric(accelerator="auto", precision="16-mixed")
    fabric.launch()
    
    # åŠ è½½è¯æ±‡è¡¨
    vocab_path = 'tibetan_vocab_optimized.txt'
    with open(vocab_path, 'r', encoding='utf-8') as f:
        vocab = [line.strip() for line in f if line.strip()]
    char2idx = {char: idx for idx, char in enumerate(vocab)}
    idx2char = {idx: char for idx, char in enumerate(vocab)}
    vocab_size = len(vocab)
    
    fabric.print(f"\n{'='*60}")
    fabric.print(f"å¼€å§‹è®­ç»ƒ: {MODEL_NAMES.get(model_name, model_name)}")
    fabric.print(f"è¯æ±‡è¡¨å¤§å°: {vocab_size}")
    fabric.print(f"æ•°æ®å¢å¼ºæ¨¡å¼: {augmentation}")
    fabric.print(f"æ··åˆç²¾åº¦è®­ç»ƒ: 16bit")
    fabric.print(f"{'='*60}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model_class = MODEL_DICT.get(model_name, CNNTransformer)
    model = model_class(vocab_size)
    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    
    # ä½¿ç”¨FabricåŒ…è£…æ¨¡å‹å’Œä¼˜åŒ–å™¨
    model, optimizer = fabric.setup(model, optimizer)
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    model_files = glob.glob(str(model_dir / f"{model_name}_best_model*.pth"))
    
    if model_files:
        latest_model = max(model_files, key=os.path.getmtime)
        fabric.print(f"ğŸ” å‘ç°é¢„è®­ç»ƒæ¨¡å‹: {latest_model}")
        try:
            state_dict = fabric.load(latest_model)
            model.load_state_dict(state_dict)
            fabric.print("âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œç»§ç»­è®­ç»ƒ")
        except Exception as e:
            fabric.print(f"âŒ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            fabric.print("ğŸ†• ä»å¤´å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹")
    else:
        fabric.print("ğŸ“ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶")
        fabric.print("ğŸ†• ä»å¤´å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹")
    
    # é…ç½®æ•°æ®å¢å¼º
    transform_map = {
        'none': transforms.Compose([
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((64, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ]),
        'light': get_light_augmentation(),
        'medium': get_ocr_transforms(train=True),
        'heavy': get_heavy_augmentation()
    }
    
    train_transform = transform_map.get(augmentation, get_ocr_transforms(train=True))
    val_transform = get_ocr_transforms(train=False)
    
    # æ•°æ®åŠ è½½
    train_dataset = OCRDataset('data/train_new.json', vocab_path, transform=train_transform)
    val_dataset = OCRDataset('data/val_new.json', vocab_path, transform=val_transform)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2, persistent_workers=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=2, persistent_workers=True)
    
    # ä½¿ç”¨FabricåŒ…è£…æ•°æ®åŠ è½½å™¨
    train_loader = fabric.setup_dataloaders(train_loader)
    val_loader = fabric.setup_dataloaders(val_loader)
    
    fabric.print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    fabric.print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}")
    
    # è®­ç»ƒå¾ªç¯
    best_val_wrr = 0.0
    results = {
        'epoch': [],
        'train_loss': [],
        'val_loss': [],
        'wrr': [],
        'crr': [],
        'cer': []
    }
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        num_batches = 0
        
        for i, (images, texts, text_lengths, raw_texts) in enumerate(train_loader):
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            logits = model(images)
            loss = compute_loss(logits, texts, text_lengths, blank=0)
            
            # æ£€æŸ¥æŸå¤±æœ‰æ•ˆæ€§
            if torch.isnan(loss) or torch.isinf(loss):
                fabric.print(f"âš ï¸ æŸå¤±æ— æ•ˆ: {loss.item()}")
                continue
            
            # ä½¿ç”¨Fabricçš„åå‘ä¼ æ’­ (è‡ªåŠ¨å¤„ç†16bitç²¾åº¦)
            fabric.backward(loss)
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
            optimizer.step()
            
            total_loss += loss.item()
            num_batches += 1
            
            if (i + 1) % 20 == 0:
                avg_loss = total_loss / num_batches
                fabric.print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}], Loss: {avg_loss:.4f}')
        
        # è®°å½•è®­ç»ƒæŸå¤±
        avg_train_loss = total_loss / num_batches if num_batches > 0 else 0
        results['epoch'].append(epoch + 1)
        results['train_loss'].append(avg_train_loss)
        
        # æ¯5ä¸ªepochå®Œæ•´éªŒè¯
        if (epoch + 1) % 5 == 0 or epoch == 0:
            val_metrics = validate_model(fabric, model, val_loader, idx2char, epoch + 1)
            
            # è®°å½•éªŒè¯æŒ‡æ ‡
            results['val_loss'].append(val_metrics['val_loss'])
            results['wrr'].append(val_metrics['wrr'])
            results['crr'].append(val_metrics['crr'])
            results['cer'].append(val_metrics['cer'])
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['wrr'] > best_val_wrr:
                best_val_wrr = val_metrics['wrr']
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                model_filename = str(model_dir / f"{model_name}_best_model_{timestamp}_{epoch}.pth")
                fabric.save(model_filename, model.state_dict())
                fabric.print(f'ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {model_filename}, WRR: {val_metrics["wrr"]:.2f}%')
        else:
            fabric.print(f'Epoch [{epoch + 1}/{epochs}] è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}')
    
    fabric.print(f"ğŸ‰ {MODEL_NAMES.get(model_name, model_name)} è®­ç»ƒå®Œæˆ!")
    
    # ä¿å­˜è®­ç»ƒç»“æœ
    save_results(results, model_name)
    
    return results

def validate_model(fabric, model, val_loader, idx2char, epoch):
    """éªŒè¯æ¨¡å‹æ€§èƒ½"""
    model.eval()
    all_preds = []
    all_true = []
    val_loss = 0
    val_batches = 0
    
    with torch.no_grad():
        for images, texts, text_lengths, raw_texts in val_loader:
            logits = model(images)
            loss = compute_loss(logits, texts, text_lengths, blank=0)
            
            val_loss += loss.item()
            val_batches += 1
            
            preds = decode_predictions(logits, idx2char, blank=0)
            all_preds.extend(preds)
            all_true.extend(raw_texts)
    
    avg_val_loss = val_loss / val_batches if val_batches > 0 else 0
    WRR, WRR_IF, correct, correct_one_error = compute_metrics(all_preds, all_true)
    CRR, total_chars, correct_chars = compute_crr(all_preds, all_true)
    CER = 100.0 - CRR  # å­—ç¬¦é”™è¯¯ç‡ = 100% - å­—ç¬¦æ­£ç¡®ç‡
    
    # è®¡ç®—æ’å…¥ã€åˆ é™¤å’Œæ›¿æ¢é”™è¯¯ç‡
    (ins_err_rate, total_ins, 
     del_err_rate, total_del, 
     sub_err_rate, total_sub,
     _) = compute_error_rates(all_preds, all_true)
    
    fabric.print(f'\nğŸ“Š Epoch {epoch} éªŒè¯ç»“æœ:')
    fabric.print(f'éªŒè¯æŸå¤±: {avg_val_loss:.4f}')
    fabric.print(f'WRR: {WRR:.2f}% ({correct}/{len(all_true)})')
    fabric.print(f'WRR_IF: {WRR_IF:.2f}% ({correct_one_error}/{len(all_true)})')
    fabric.print(f'CRR: {CRR:.2f}% ({correct_chars}/{total_chars})')
    fabric.print(f'CER: {CER:.2f}% ({total_chars-correct_chars}/{total_chars})')
    fabric.print(f'æ’å…¥é”™è¯¯ç‡: {ins_err_rate:.2f}% ({total_ins}/{total_chars})')
    fabric.print(f'åˆ é™¤é”™è¯¯ç‡: {del_err_rate:.2f}% ({total_del}/{total_chars})')
    fabric.print(f'æ›¿æ¢é”™è¯¯ç‡: {sub_err_rate:.2f}% ({total_sub}/{total_chars})')
    
    # æ˜¾ç¤ºé¢„æµ‹ç¤ºä¾‹
    fabric.print("ğŸ“ é¢„æµ‹ç¤ºä¾‹:")
    for i in range(min(3, len(all_preds))):
        fabric.print(f"  çœŸå®: '{all_true[i]}'")
        fabric.print(f"  é¢„æµ‹: '{all_preds[i]}'")
    
    # è¿”å›éªŒè¯æŒ‡æ ‡
    return {
        'val_loss': avg_val_loss,
        'wrr': WRR,
        'wrr_if': WRR_IF,
        'crr': CRR,
        'cer': CER,
        'ins_err': ins_err_rate,
        'del_err': del_err_rate,
        'sub_err': sub_err_rate
    }

def save_results(results, model_name):
    """ä¿å­˜è®­ç»ƒç»“æœåˆ°æ–‡ä»¶"""
    results_dir = Path('results')
    results_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    np.save(results_dir / f"{model_name}_results.npy", results)
    
    # ç”Ÿæˆå¹¶ä¿å­˜è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(12, 10))
    
    # æŸå¤±æ›²çº¿
    plt.subplot(2, 1, 1)
    plt.plot(results['epoch'], results['train_loss'], label='è®­ç»ƒæŸå¤±')
    if results['val_loss']:
        val_epochs = [results['epoch'][i] for i in range(len(results['epoch'])) if i % 5 == 0 or i == 0]
        plt.plot(val_epochs, results['val_loss'], 'o-', label='éªŒè¯æŸå¤±')
    plt.title(f'{MODEL_NAMES.get(model_name, model_name)} - æŸå¤±æ›²çº¿')
    plt.xlabel('è½®æ•°')
    plt.ylabel('æŸå¤±')
    plt.legend()
    plt.grid(True)
    
    # å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(2, 1, 2)
    if results['wrr']:
        val_epochs = [results['epoch'][i] for i in range(len(results['epoch'])) if i % 5 == 0 or i == 0]
        plt.plot(val_epochs, results['wrr'], 'o-', label='WRR')
        plt.plot(val_epochs, results['crr'], 'o-', label='CRR')
        plt.plot(val_epochs, results['cer'], 'o-', label='CER')
    plt.title(f'{MODEL_NAMES.get(model_name, model_name)} - è¯†åˆ«ç‡æ›²çº¿')
    plt.xlabel('è½®æ•°')
    plt.ylabel('ç™¾åˆ†æ¯”(%)')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(results_dir / f"{model_name}_curves.png")

def compare_models(all_results):
    """æ¯”è¾ƒä¸åŒæ¨¡å‹çš„ç»“æœï¼Œç”Ÿæˆæ¯”è¾ƒå›¾è¡¨"""
    results_dir = Path('results')
    results_dir.mkdir(exist_ok=True)
    
    # å‡†å¤‡æ•°æ®
    model_names = list(all_results.keys())
    final_wrr = [all_results[name]['wrr'][-1] for name in model_names]
    final_crr = [all_results[name]['crr'][-1] for name in model_names]
    final_cer = [all_results[name]['cer'][-1] for name in model_names]
    
    # ç”Ÿæˆæ¯”è¾ƒæŸ±çŠ¶å›¾
    plt.figure(figsize=(14, 8))
    
    # WRRæ¯”è¾ƒ
    plt.subplot(1, 3, 1)
    x = np.arange(len(model_names))
    bar_width = 0.7
    plt.bar(x, final_wrr, width=bar_width, alpha=0.8, label='æ¨¡å‹')
    plt.title('è¯è¯†åˆ«ç‡(WRR)æ¯”è¾ƒ')
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('WRR (%)')
    plt.xticks(x, [MODEL_NAMES.get(name, name) for name in model_names], rotation=45)
    plt.grid(axis='y', alpha=0.3)
    
    # CRRæ¯”è¾ƒ
    plt.subplot(1, 3, 2)
    plt.bar(x, final_crr, width=bar_width, alpha=0.8)
    plt.title('å­—ç¬¦è¯†åˆ«ç‡(CRR)æ¯”è¾ƒ')
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('CRR (%)')
    plt.xticks(x, [MODEL_NAMES.get(name, name) for name in model_names], rotation=45)
    plt.grid(axis='y', alpha=0.3)
    
    # CERæ¯”è¾ƒ
    plt.subplot(1, 3, 3)
    plt.bar(x, final_cer, width=bar_width, alpha=0.8)
    plt.title('å­—ç¬¦é”™è¯¯ç‡(CER)æ¯”è¾ƒ')
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('CER (%)')
    plt.xticks(x, [MODEL_NAMES.get(name, name) for name in model_names], rotation=45)
    plt.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(results_dir / "model_comparison.png")
    
    # æ‰“å°æ¯”è¾ƒè¡¨æ ¼
    print("\n\næ¨¡å‹æ€§èƒ½æ¯”è¾ƒè¡¨ï¼š")
    print("=" * 80)
    print(f"{'æ¨¡å‹åç§°':<20} {'WRR (%)':<10} {'CRR (%)':<10} {'CER (%)':<10}")
    print("-" * 80)
    for i, name in enumerate(model_names):
        print(f"{MODEL_NAMES.get(name, name):<20} {final_wrr[i]:<10.2f} {final_crr[i]:<10.2f} {final_cer[i]:<10.2f}")
    print("=" * 80)

def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒå¹¶æ¯”è¾ƒå¤šç§è—æ–‡OCRæ¨¡å‹')
    parser.add_argument('--models', '-m', nargs='+', 
                        choices=['base', 'residual', 'fpn', 'attention', 'bilstm', 'all'],
                        default=['all'],
                        help='è¦è®­ç»ƒçš„æ¨¡å‹ (default: all)')
    parser.add_argument('--augmentation', '-a', 
                       choices=['none', 'light', 'medium', 'heavy'], 
                       default='medium',
                       help='æ•°æ®å¢å¼ºå¼ºåº¦ (default: medium)')
    parser.add_argument('--epochs', '-e', type=int, default=300,
                       help='æ¯ä¸ªæ¨¡å‹çš„è®­ç»ƒè½®æ•° (default: 50)')
    parser.add_argument('--batch-size', '-b', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å° (default: 16)')
    parser.add_argument('--lr', type=float, default=1e-4,
                       help='å­¦ä¹ ç‡ (default: 0.0001)')
    
    args = parser.parse_args()
    
    print("\n" + "=" * 60)
    print(f"{'è—æ–‡OCRå¤šæ¨¡å‹è®­ç»ƒä¸æ¯”è¾ƒ':^60}")
    print("=" * 60)
    print(f"âš¡ è¿è¡Œç¯å¢ƒ: Windows")
    print(f"ğŸš€ æ··åˆç²¾åº¦: 16bit")
    print(f"ğŸ“ˆ æ•°æ®å¢å¼º: {args.augmentation}")
    print(f"ğŸ”„ æ¯æ¨¡å‹è½®æ•°: {args.epochs}")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"ğŸ“Š å­¦ä¹ ç‡: {args.lr}")
    print("-" * 60)
    
    # ç¡®å®šè¦è®­ç»ƒçš„æ¨¡å‹
    models_to_train = []
    if 'all' in args.models:
        models_to_train = list(MODEL_DICT.keys())
    else:
        models_to_train = args.models
    
    # è®°å½•æ¯ä¸ªæ¨¡å‹çš„ç»“æœ
    all_results = {}
    total_start_time = time.time()
    
    # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
    for model_name in models_to_train:
        print(f"\nå¼€å§‹è®­ç»ƒæ¨¡å‹: {MODEL_NAMES.get(model_name, model_name)}")
        start_time = time.time()
        
        results = train_model(
            model_name=model_name,
            augmentation=args.augmentation,
            epochs=args.epochs,
            batch_size=args.batch_size,
            lr=args.lr
        )
        
        all_results[model_name] = results
        
        elapsed = time.time() - start_time
        print(f"{MODEL_NAMES.get(model_name, model_name)} è®­ç»ƒå®Œæˆï¼Œç”¨æ—¶: {elapsed/60:.2f}åˆ†é’Ÿ")
    
    total_elapsed = time.time() - total_start_time
    print(f"\næ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ€»ç”¨æ—¶: {total_elapsed/60:.2f}åˆ†é’Ÿ")
    
    # æ¯”è¾ƒæ¨¡å‹æ€§èƒ½
    if len(models_to_train) > 1:
        compare_models(all_results)

if __name__ == '__main__':
    main() 